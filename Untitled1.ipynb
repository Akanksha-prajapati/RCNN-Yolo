{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFXvF6Ub+Tqdi4IzR1HZUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akanksha-prajapati/RCNN-Yolo/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4fJ_GmXqeSC"
      },
      "outputs": [],
      "source": [
        "# 1. How do you load and run inference on a custom image using the YOLOv8 model (labeled as YOLOv9)?\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model (considered as YOLOv9 in this context)\n",
        "model = YOLO(\"yolov8n.pt\")  # Change to \"yolov9.pt\" if available\n",
        "\n",
        "# Run inference on a custom image\n",
        "results = model(\"custom_image.jpg\")\n",
        "\n",
        "# Display results\n",
        "results.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. How do you load the Faster R-CNN model with a ResNet50 backbone and print its architecture?\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "# Load Faster R-CNN with ResNet50 backbone\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "zdQiHdgsquog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. How do you perform inference on an online image using the Faster R-CNN model and print the predictions?\n",
        "\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "# Load Faster R-CNN\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load image from URL\n",
        "url = \"https://example.com/image.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Transform image for model input\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    predictions = model(image_tensor)\n",
        "\n",
        "# Print predictions\n",
        "print(predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "EMeW5V50q4WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. How do you load an image and perform inference using YOLOv9, then display the detected objects with bounding boxes and class labels?\n",
        "\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Run inference\n",
        "results = model(\"image.jpg\")\n",
        "\n",
        "# Display results with bounding boxes and labels\n",
        "results.show()\n"
      ],
      "metadata": {
        "id": "Wp1DokZyrBJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. How do you display bounding boxes for the detected objects in an image using Faster R-CNN?\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "\n",
        "# Load Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load image\n",
        "image_path = \"image.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Transform image\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    predictions = model(image_tensor)\n",
        "\n",
        "# Convert image to OpenCV format\n",
        "image_cv = cv2.imread(image_path)\n",
        "\n",
        "# Draw bounding boxes\n",
        "for i in range(len(predictions[0][\"boxes\"])):\n",
        "    box = predictions[0][\"boxes\"][i].numpy()\n",
        "    score = predictions[0][\"scores\"][i].item()\n",
        "\n",
        "    if score > 0.5:  # Confidence threshold\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(image_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image_cv, f\"{score:.2f}\", (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Show image\n",
        "cv2.imshow(\"Detected Objects\", image_cv)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "ReqpqEMTrKtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. How can you change the confidence threshold for YOLO object detection and filter out low-confidence predictions?\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Run inference with a confidence threshold of 0.7\n",
        "results = model(\"image.jpg\", conf=0.7)\n",
        "\n",
        "# Display results\n",
        "results.show()\n"
      ],
      "metadata": {
        "id": "paR2zBhSrjDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. How do you plot the training and validation loss curves for model evaluation?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume losses are stored during training\n",
        "train_loss = [0.8, 0.6, 0.4, 0.3, 0.2]\n",
        "val_loss = [0.9, 0.7, 0.5, 0.4, 0.3]\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot loss curves\n",
        "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mYEVR5zTrsOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. How do you perform inference on multiple images from a local folder using Faster R-CNN and display the bounding boxes for each?\n",
        "\n",
        "\n",
        " import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Load Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = \"images/\"\n",
        "\n",
        "# Iterate through images in the folder\n",
        "for image_name in os.listdir(image_folder):\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Transform image\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    # Convert to OpenCV format\n",
        "    image_cv = cv2.imread(image_path)\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for i in range(len(predictions[0][\"boxes\"])):\n",
        "        box = predictions[0][\"boxes\"][i].numpy()\n",
        "        score = predictions[0][\"scores\"][i].item()\n",
        "\n",
        "        if score > 0.5:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cv2.rectangle(image_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Show image\n",
        "    cv2.imshow(\"Detected Objects\", image_cv)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "R4Txdi2vrzey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. How can you save the inference results (with bounding boxes) as a new image after performing detection using YOLO?\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Run inference\n",
        "results = model(\"image.jpg\")\n",
        "\n",
        "# Save the image with detected objects\n",
        "results.save(filename=\"output.jpg\")\n"
      ],
      "metadata": {
        "id": "p6F5H4iyr8Rh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}